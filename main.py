# Importamos las librer√≠as necesarias
import pandas as pd  # Para manejar datos en formato tabular (DataFrames)
import numpy as np  # Para c√°lculos num√©ricos (aunque aqu√≠ no se usa directamente)
import re  # Para usar expresiones regulares y limpiar texto
import nltk  # Librer√≠a para procesamiento de lenguaje natural
from nltk.corpus import stopwords  # Para eliminar palabras vac√≠as (como "the", "is", "in", etc.)
from nltk.stem import PorterStemmer  # Para aplicar stemming (reducir palabras a su ra√≠z)

# Descargamos las stopwords de NLTK (solo la primera vez que ejecutes el script)
nltk.download("stopwords")

# Creamos el objeto "stemmer" (para aplicar el algoritmo de stemming de Porter)
stemmer = PorterStemmer()

# Cargamos las stopwords del idioma ingl√©s y las convertimos en un conjunto (m√°s eficiente para b√∫squeda)
stop_words = set(stopwords.words("english"))

# ----------------------------------------------------------------------
# 1Ô∏è‚É£ Cargar el dataset original
# ----------------------------------------------------------------------
# Leemos el archivo CSV que contiene los mensajes de texto y sus etiquetas ("ham" o "spam")
# La codificaci√≥n "latin-1" se usa porque el archivo puede contener caracteres especiales
# Solo seleccionamos las columnas 'v1' (etiqueta) y 'v2' (mensaje)
df = pd.read_csv("files/spam.csv", encoding="latin-1")[["v1", "v2"]]

# ----------------------------------------------------------------------
# 2Ô∏è‚É£ Renombrar columnas para mayor claridad
# ----------------------------------------------------------------------
# Cambiamos los nombres originales ("v1", "v2") por nombres m√°s descriptivos:
# "label" ‚Üí etiqueta (ham/spam)
# "message" ‚Üí texto del mensaje
df.columns = ["label", "message"]

# ----------------------------------------------------------------------
# 3Ô∏è‚É£ Convertir etiquetas a valores binarios
# ----------------------------------------------------------------------
# Transformamos las etiquetas de texto a n√∫meros:
# Si la etiqueta es "ham" ‚Üí 0 (mensaje normal)
# Si la etiqueta es "spam" ‚Üí 1 (mensaje de spam)
df["label"] = df["label"].apply(lambda x: 0 if x == "ham" else 1)

# Mostramos las primeras filas para comprobar
print(df.head())


# ----------------------------------------------------------------------
# 4Ô∏è‚É£ Definir una funci√≥n de preprocesamiento del texto
# ----------------------------------------------------------------------
def proprocess_text(text):
    # üîπ Eliminamos todos los caracteres que no sean letras o n√∫meros (dejamos espacios)
    text = re.sub(r"\W", " ", text)

    # üîπ Convertimos todo el texto a min√∫sculas
    text = text.lower()

    # üîπ Dividimos el texto en palabras individuales
    words = text.split()

    # üîπ Aplicamos stemming a cada palabra (reduce "running", "runs", "ran" ‚Üí "run")
    #     y eliminamos las stopwords (palabras sin valor sem√°ntico relevante)
    words = [stemmer.stem(word) for word in words if word not in stop_words]

    # üîπ Volvemos a unir las palabras procesadas en una sola cadena de texto
    return " ".join(words)


# ----------------------------------------------------------------------
# 5Ô∏è‚É£ Aplicar la limpieza a la columna 'message'
# ----------------------------------------------------------------------
# Creamos una nueva columna llamada "cleaned_message"
# que contiene la versi√≥n procesada de cada mensaje original
df["cleaned_message"] = df["message"].apply(proprocess_text)

# Mostramos las primeras filas para verificar el resultado
print(df.head())
